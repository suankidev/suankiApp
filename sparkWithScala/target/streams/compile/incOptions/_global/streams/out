[0m[[0m[0mdebug[0m] [0m[0mCreated transactional ClassFileManager with tempDir = C:\Users\sujee\OneDrive\Documents\bigdata_and_hadoop\sparkDev\sparkWithScala\target\scala-2.13\classes.bak[0m
[0m[[0m[0mdebug[0m] [0m[0mAbout to delete class files:[0m
[0m[[0m[0mdebug[0m] [0m[0m	Init.class[0m
[0m[[0m[0mdebug[0m] [0m[0m	Init$delayedInit$body.class[0m
[0m[[0m[0mdebug[0m] [0m[0m	Init$.class[0m
[0m[[0m[0mdebug[0m] [0m[0mWe backup class files:[0m
[0m[[0m[0mdebug[0m] [0m[0m	Init.class[0m
[0m[[0m[0mdebug[0m] [0m[0m	Init$delayedInit$body.class[0m
[0m[[0m[0mdebug[0m] [0m[0m	Init$.class[0m
[0m[[0m[0mdebug[0m] [0m[0mRegistering generated classes:[0m
[0m[[0m[0mdebug[0m] [0m[0m	Init.class[0m
[0m[[0m[0mdebug[0m] [0m[0m	Init$delayedInit$body.class[0m
[0m[[0m[0mdebug[0m] [0m[0m	Init$.class[0m
[0m[[0m[0mdebug[0m] [0m[0mRemoving the temporary directory used for backing up class files: C:\Users\sujee\OneDrive\Documents\bigdata_and_hadoop\sparkDev\sparkWithScala\target\scala-2.13\classes.bak[0m
